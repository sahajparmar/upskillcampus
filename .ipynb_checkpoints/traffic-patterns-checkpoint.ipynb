{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1558075e-6d9a-4854-83c7-8063595893d3",
    "_uuid": "5084de8bf0da7028a3a8a0214d6ede184c210d38",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a2cdc588-c28f-498b-93fd-d1f9e4083bb3",
    "_uuid": "2464efb94360c24315a8287cdad99d588b989a47"
   },
   "source": [
    "My Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "6a2aba18-9611-470e-a815-860e1612b50e",
    "_uuid": "cdbc56fc0aad01b0513da3a8786859dd0368f662",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def datetounix(df):\n",
    "    # Initialising unixtime list\n",
    "    unixtime = []\n",
    "    \n",
    "    # Running a loop for converting Date to seconds\n",
    "    for date in df['DateTime']:\n",
    "        unixtime.append(time.mktime(date.timetuple()))\n",
    "    \n",
    "    # Replacing Date with unixtime list\n",
    "    df['DateTime'] = unixtime\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "3c72886a-4c88-4291-ae40-9d6f82f014d5",
    "_uuid": "21c762cd0c13e800bbbc257efa098d69a8f33b84"
   },
   "source": [
    "Importing all the Libraries at one go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "11641bdc-752e-44f0-a924-6291a7d0d9e3",
    "_uuid": "ce91bc917dbee42dc80c3da4494fab5f466def74",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# import libs\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import time\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import operator\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4371b3dc-5290-40d9-bb99-1437871d10dd",
    "_uuid": "b492582468ef1f654cdbb711d6aa52051b36ef11"
   },
   "source": [
    "**Data Cleaning**\n",
    "\n",
    "First task at hand is data cleaning. Loading Data from dataset and cleaning it up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "85387a1b-d2b6-49cf-9ca9-571781c62f99",
    "_uuid": "e124dca8fb995d66210a50b7f37f56043c616d06",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# read train dataframe\n",
    "# file_path = os.path.join(os.path.abspath(''), '../input/train_aWnotuB.csv')\n",
    "df_train = pd.read_csv('../input/train_aWnotuB.csv', encoding='ISO-8859-1', engine='c')\n",
    "\n",
    "# read test dataframe\n",
    "# file_path = os.path.join(os.path.abspath(''), '../input/test_BdBKkAj.csv')\n",
    "df_test = pd.read_csv('../input/test_BdBKkAj.csv', encoding='ISO-8859-1', engine='c')\n",
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "7c162a11-a252-4d55-bad9-c5da9b194204",
    "_uuid": "206e250311997e92092d907da51f6cbfae3dd865",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Converting to datetime\n",
    "df_train['DateTime'] = pd.to_datetime(df_train['DateTime'])\n",
    "df_test['DateTime'] = pd.to_datetime(df_test['DateTime'])\n",
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "26ca1a09-d9e0-4669-95e0-659e09b22bc4",
    "_uuid": "30c7856d9e7ab105b80824d724948634263a7e4b",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Creating features from DateTime for train data\n",
    "\n",
    "df_test['Weekday'] = [datetime.weekday(date) for date in df_test.DateTime]\n",
    "df_test['Year'] = [date.year for date in df_test.DateTime]\n",
    "df_test['Month'] = [date.month for date in df_test.DateTime]\n",
    "df_test['Day'] = [date.day for date in df_test.DateTime]\n",
    "df_test['Time'] = [((date.hour*60+(date.minute))*60)+date.second for date in df_test.DateTime]\n",
    "df_test['Week'] = [date.week for date in df_test.DateTime]\n",
    "df_test['Quarter'] = [date.quarter for date in df_test.DateTime]\n",
    "\n",
    "# Creating features from DateTime for test data\n",
    "\n",
    "df_train['Weekday'] = [datetime.weekday(date) for date in df_train.DateTime]\n",
    "df_train['Year'] = [date.year for date in df_train.DateTime]\n",
    "df_train['Month'] = [date.month for date in df_train.DateTime]\n",
    "df_train['Day'] = [date.day for date in df_train.DateTime]\n",
    "df_train['Time'] = [((date.hour*60+(date.minute))*60)+date.second for date in df_train.DateTime]\n",
    "df_train['Week'] = [date.week for date in df_train.DateTime]\n",
    "df_train['Quarter'] = [date.quarter for date in df_train.DateTime]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "64608091-eb88-47c6-811d-14cd1003f432",
    "_uuid": "0243d5d341203394169cd0b6f2ca9782a2c46282"
   },
   "source": [
    "Analysis: To assess next steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "46e7341a-fda9-4294-aff4-d4424be112ad",
    "_uuid": "5b735d4300a4cc6b112fb4062b92398a69fdc6f1",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# create an instance for tree feature selection\n",
    "tree_clf = ExtraTreesClassifier()\n",
    "\n",
    "# first create arrays holding input and output data\n",
    "# get the features into an array X\n",
    "# remove target column from the df\n",
    "df_train_features = df_train.drop(['Vehicles'], axis=1)\n",
    "\n",
    "# Convet timestamp to seconds\n",
    "df_train_features = datetounix(df_train_features)\n",
    "\n",
    "# store features in X array\n",
    "X = df_train_features.values\n",
    "\n",
    "# Store target feature in y array\n",
    "y = df_train['Vehicles'].values\n",
    "\n",
    "# fit the model\n",
    "tree_clf.fit(X, y)\n",
    "\n",
    "# Preparing variables\n",
    "importances = tree_clf.feature_importances_\n",
    "feature_names = df_train_features.columns.tolist()\n",
    "\n",
    "feature_imp_dict = dict(zip(feature_names, importances))\n",
    "sorted_features = sorted(feature_imp_dict.items(), key=operator.itemgetter(1), reverse=True)\n",
    "\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(X.shape[1]):\n",
    "    print(\"feature %d : %s (%f)\" % (indices[f], sorted_features[f][0], sorted_features[f][1]))\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure(0)\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X.shape[1]), importances[indices],\n",
    "       color=\"r\", align=\"center\")\n",
    "plt.xticks(range(X.shape[1]), indices)\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0fa3e3df-5ab3-4ef7-80e6-170df3e16fba",
    "_uuid": "9b8acbaf1103fda2bd9820a61088b92c8d7a7565",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Visualising the histogram for positive reviews only from train and dataset\n",
    "data = df_train.Vehicles\n",
    "binwidth = 1\n",
    "plt.hist(data, bins=range(min(data), max(data) + binwidth, binwidth), log=False)\n",
    "plt.title(\"Gaussian Histogram\")\n",
    "plt.xlabel(\"Traffic\")\n",
    "plt.ylabel(\"Number of times\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e1225358-db09-43eb-a249-03eb6d5dcfb0",
    "_uuid": "5bf9158093c8bbfda0793fa6e2a4a7d98c52a91f"
   },
   "source": [
    "Data Preparation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "022e970c-1156-4b84-ab06-0441d2699d53",
    "_uuid": "8d6ff3314cb5ce06d730af386fb22e01f253b5d8",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "######################################## X_test creation for Prediction #################################\n",
    "\n",
    "# Convert timestamp to seconds\n",
    "df_test_features = datetounix(df_test.drop(['Year', 'Quarter', 'Month', 'ID'], axis=1))\n",
    "\n",
    "# Create X_test from the test set\n",
    "\n",
    "X_test = df_test_features.values\n",
    "\n",
    "######################################## Dropping Features from train set #######################\n",
    "\n",
    "df_train_features = df_train.drop(['Vehicles','Year', 'Quarter', 'Month', 'ID'], axis=1)\n",
    "\n",
    "# Convert timestamp to seconds\n",
    "df_train_features = datetounix(df_train_features)\n",
    "\n",
    "# store features in X array\n",
    "X = df_train_features.values\n",
    "\n",
    "# store target in y array\n",
    "y = df_train['Vehicles'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "966dbc28-0db9-4699-b9b6-34ab03ebb4e6",
    "_uuid": "dada81970defda3f963bd720b7274ab25fefa101"
   },
   "source": [
    "Using Decision Tree to Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "86ae9029-5f38-4288-afc8-d10b62a33ff7",
    "_uuid": "02444494650b0d0252b50023bea898347bc6ca5e",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Data prep\n",
    "df_solution = pd.DataFrame()\n",
    "df_solution['ID'] = df_test.ID\n",
    "\n",
    "# Starting time for time calculations\n",
    "start_time = time.time()\n",
    "\n",
    "# Create decision tree object\n",
    "clf = DecisionTreeClassifier(criterion='gini', random_state = 13)\n",
    "\n",
    "# fit the model\n",
    "clf.fit(X, y)\n",
    "\n",
    "# predict the outcome for testing data\n",
    "predictions = clf.predict(X_test)\n",
    "\n",
    "print(\"The time taken to execute is %s seconds\" % (time.time() - start_time))\n",
    "\n",
    "# Prepare Solution dataframe\n",
    "df_solution['Vehicles'] = predictions\n",
    "df_solution"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
